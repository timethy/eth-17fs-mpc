\documentclass[landscape,a4paper,8pt]{scrartcl}

\usepackage{bm}
\usepackage{layout}
\usepackage{changepage}   % for the adjustwidth environment
\usepackage{booktabs}
%\usepackage{extsizes}
%\usepackage{savetrees}
\usepackage{xargs} 
\usepackage{graphicx,xcolor} 
\usepackage[bordercolor=white,backgroundcolor=gray!30,linecolor=black,colorinlistoftodos]{todonotes}
\newcommandx{\tim}[1]{\todo[color=blue!30, inline]{tim: {#1}}}

%------------------------------------
%  FOOTER SETTINGS
%------------------------------------
\pagestyle{fancy}
\renewcommand{\headrulewidth}{0pt}
\fancyhead{}
\renewcommand{\footrulewidth}{0.5pt}
\fancyfoot[L]{\footnotesize\color{dkgreen} Tim Taubner, Jen Wei Niam; \href{https://github.com/timethy/mpc}{www.github.com/timethy/mpc}}
\fancyfoot[C]{\footnotesize\color{dkgreen} Model Predictive Control -- \today}
\fancyfoot[RO, LE] {\footnotesize\color{dkgreen} \thepage}

\newcommand{\remph}[1]{{\textcolor{red}{#1}}}
\newcommand{\mc}[1]{\mathcal{#1}}
\newcommand{\R}{\mathbb R}
\newcommand\va{\bm{a}}
\newcommand\vb{\bm{b}}
\newcommand\vq{\bm{q}}
\newcommand\vr{\bm{r}}
\newcommand\vp{\bm{p}}
\newcommand\vk{\bm{k}}
\newcommand\vn{\bm{n}}
\newcommand\vv{\bm{v}}
\newcommand\vx{\bm{x}}
\newcommand\vy{\bm{y}}
\newcommand\vz{\bm{z}}
\newcommand\vA{\bm{A}}
\newcommand\vB{\bm{B}}
\newcommand\vC{\bm{C}}
\newcommand\vD{\bm{D}}
\newcommand\vE{\bm{E}}
\newcommand\vF{\bm{F}}
\newcommand\vG{\bm{G}}
\newcommand\vH{\bm{H}}
\newcommand\vI{\bm{I}}
\newcommand\vK{\bm{K}}
\newcommand\vL{\bm{L}}
\newcommand\vM{\bm{M}}
\newcommand\vN{\bm{N}}
\newcommand\vP{\bm{P}}
\newcommand\vQ{\bm{Q}}
\newcommand\vR{\bm{R}}
\newcommand\vS{\bm{S}}
\newcommand\vT{\bm{T}}
\newcommand\vU{\bm{U}}
\newcommand\vV{\bm{V}}
\newcommand\vW{\bm{W}}
\newcommand\vX{\bm{X}}
\newcommand\vY{\bm{Y}}
\newcommand\vZ{\bm{Z}}

\newcommand{\Mn}[1]{\begin{pmatrix}#1\end{pmatrix}} %normale Klammern, normal bracket
\newcommand{\Mo}[1]{\begin{matrix}#1\end{matrix}} %ohne Klammern, no brackets
\newcommand{\Me}[1]{\begin{bmatrix}#1\end{bmatrix}} %eckige Klammern
\newcommand{\Mg}[1]{\begin{Bmatrix}#1\end{Bmatrix}} %geschweifte Klammern

\DeclareMathOperator\diag{diag}
\DeclareMathOperator\pre{pre}
\DeclareMathOperator\norm{norm}
\DeclareMathOperator\rank{rank}
\DeclareMathOperator\dom{dom}
\DeclareMathOperator\size{size}

%------------------------------------
%  BEGIN DOCUMENT
%------------------------------------

\begin{document}
\raggedright
%\sffamily

%--CONTENT--
\begin{multicols*}{3}
\section{System Theory}
\begin{align*}
\dot{x}(t) &= A^cx(t)+B^cu(t)\\
y(t) &= C^cx(t) + D^cu(t)\\
x(t) &= e^{A^c(t-t_0)}x_0+\int_{t_0}^te^{A^c(t-\tau)}Bu(\tau)d\tau \\
e^{A^ct}&=\sum_{n=0}^\infty\frac{(A^ct)^n}{n!} \\
x(k+N)&=A^Nx(k)+\sum_{i=0}^{N-1}A^iBu(k+N-1-i)
\end{align*}

\subsection{Nonlinear Systems}
we define a system to be stable in the sense of Lyapunov, if it stays in any arbitrarily small neighborhood of the origin when it is disturbed slightly
\subsection{Lyapunov Stability}
\textbf{Lyapunov stable} if for every $\epsilon > 0$ there exists a $\delta(\epsilon)$ such that
\[ \norm{x(0)}<\delta(\epsilon)\to \norm{x(k)} < \epsilon, \forall k \geq 0 \]
\textbf{asymptotically stable} in $\Omega\subseteq \R^n$ if it is Lyapunov stable and attractive $\lim_{k\to\infty}x(k)=0, \forall x(0)\in \Omega$
\subsection{Lyapunov Function}
Consider the equilibrium point $x=0$. Let $\Omega\subset\R^n$ be a closed and bounded set containing the origin. A function $V:\R^n\to \R$, continous at the origin, finite for every $x\in \Omega$, and such that 
\begin{align*}
V(0)=0 \text{ and } V(x)>0, \forall x\in \Omega \backslash \{0\}\\
V(g(x))-V(x)\leq -\alpha(x), \forall x\in\Omega\backslash \{0\}
\end{align*}
where $\alpha:\R^n\to\R$ is continuous positive definite

If a system admins a Lyapunov function $V(x)$, then $x=0$ is \textbf{asymptotically stable} in $\Omega$ (sufficient but not necessary)

If a system admits a Lyapunov function, which additionally satisfies $\norm{x}\to \infty \rightarrow V(x)\to \infty$, then $x=0$ is \textbf{globally asymptotically stable}

\tim{Check Eig. values of $(APA-P)$ neg., $V(x) = x^TPx$ ?}

\textbf{Linear systems}: iff eigenvalues of $A$ inside unit circle (i.e. stable) then $\exists unique \ P>0$ that solves $A_{cl}^TPA_{cl}-P = -Q,\ Q > 0$ and $V = x^TPx$ is a lyapunov function.

\subsection{Discretization}
Euler: $A = I + T_s A^c ,\ B = T_s B^c ,\ C = C^c ,\ D = D^c $
\begin{align*}
x(k + 1) &= x(k) + T_sg^c(x(k),u(k)) = g(x(k),u(k)) \\ 
y(k) &= h^c(x(k),u(k)) = h(x(k),u(k))
\end{align*}
Exact: (assumption of a constant $u(t)$ during $T_s$)
\begin{align*}
A = e^{A^cT_s},\ B = \int_0^{T_s} e^{A^c(Ts-\tau')}B^cd\tau \\
B=(A^c)^{-1}(A-I)B^c,\ \text{if $A^c$ invertible}
\end{align*}

\subsection{Controllability (reachability) and observability}
\begin{align*}
C &= [B \ AB \ ... \ A^{n-1}B] \\
O &= [C^T \ (CA)^T \ ... \ (CA^{n-1})^T]
\end{align*}

\section{Unconstrained Control}
\subsection{Block Approach (used also for $\bar w$ substition)}
\begin{align*}
		\Me{x_0 \\ x_1 \\ \vdots \\ x_N } & = \Me{\vI \\ \vA \\ \vdots \\ \vA^N}x(0) + \Me{\bm 0 & \bm 0 & \dots & \bm 0 \\ \vB & \bm 0 & \dots & \bm 0 \\ \vA\vB & \vB & \dots & \bm 0 \\ \vdots & \vdots & \ddots & \bm 0 \\ \vA^{N-1}\vB & \dots & \vA\vB & \vB}\Me{u_0 \\ u_1 \\ \vdots \\ u_{N_1}}
\end{align*}

\begin{align*}
x & = \vS^x\cdot x(0) + \vS^u\cdot u & \size(\vS^x) & = \left[ n_\text{states} \cdot (N+1) , N \right] \\
  &                                  & \size(\vS^u) & = \left[ n_\text{states} \cdot (N+1), n_\text{states} \right] \\
\bar\vQ & = \diag(\vQ,\dots,\vQ, \vP) & \size(\bar\vQ) & = \left[ n_\text{states} \cdot (N+1), n_\text{states} \cdot (N+1) \right] \\
\bar\vR & = \diag(\vR,\dots,\vR) & \size(\bar\vR) & = \left[ n_\text{input}\cdot N, n_\text{input}\cdot N \right] \\
\vH & = {\vS^u}^T\bar\vQ\vS^u + \vR & \vF & = {\vS^x}^T\bar\vQ\vS^u \\
\vY & = {\vS^x}^T\bar\vQ\vS^x
\end{align*}
\paragraph{Optimal cost and control}
%\quad \nabla_{u_0}J^*(x_0) \mbeq 0 \text{ gives} \\
\begin{align*}
J^*(x_0) & = -x_0^T \vF\vH\vF^T x_0 + x_0^T \vY x_0 \\
u^*(x_0) & = -\vH^{-1}\vF^T x_0 = - \left( {\vS^u}^T\bar\vQ\vS^u + \vR \right)^{-1}{\vS^u}^T\bar\vQ\vS^x x_0 \\
\end{align*}

\subsection{Recursive Approach}
\begin{align*}
J_k^*(x_k) & = \min_{u_k} I(x_k, u_k) + J_{k+1}(x_{k+1})
\end{align*}
Is a feedback controller as opposed to the Batch Approach.
For LQR solve via Riccati Difference Equation (RDE).
\begin{align*}
 \vF_k & = -(\vB^T\vP_\remph{k+1}\vB + \vR)^{-1}\vB^T\vP_\remph{k+1}\vA \\
 \vP_k & = \vA^T\vP_\remph{k+1}\vA + \vQ - \vA^T\vP_\remph{k+1}\vB(\vB^T\vP_\remph{k+1}\vB + \vR)^{-1}\vB^T\vP_\remph{k+1}\vA
\end{align*}
\begin{align*}
 u_k^* & = \vF_k\ x_k  & J_k^*(x_k) & = x_k^T\vP_k\ x_k & \vP_N & = \vP
\end{align*}
For unconstrained Infinite Horizon Problem, substituting $\vP_\infty = \vP_k = \vP_{k+1}$ into RDE gives DARE.
Uniquely solvable, iff $(A,B)$ stabilizable and $(A, G)$ detectable, where $\vG\vG^T = \vQ$.
Follows from closed-loop system $x_{k+1} = (\vA + \vB\vF_k)x_k$

\section{(Convex) Optimization}
\subsection{Convexity}
\paragraph{Convex set $\mc X$} iff $\forall \lambda \in [0, 1] \forall x, y \in \mc X\ \lambda x + (1-\lambda) y \in \mc X$.
Intersection preserves convexity, union does not.
\paragraph{Affine set $\mc X$} $= \{ x \in \R^n | \vA x = b \}$ for some $\vA,b$
\paragraph{Subspace} is affine set through origin, i.e. $b = \bm 0$, aka Nullspace of $\vA$.
\paragraph{Hyperplane $\mc X$} $= \{ x \in \R^n | a^T x = b \}$ for some $a, b$.
\paragraph{Halfspace $\mc X$} $= \{ x \in \R^n | a^T x \leq b \}$ for some $a, b$.
\paragraph{Polyhedron $\mc P$} $= \{ x | a_i^Tx \leq b_i, i = 1, \dots, n \} = \{ x | \vA x \leq b \}$
\paragraph{Cone}
\paragraph{Ellipsoid $\mc E$} $= \{ x | (x-x_c)^T\vA^{-1}(x-x_c) \leq 1 \}$, $x_c$ center point.

\paragraph{Convex function}

\paragraph{Norm $f(x): \R^n \rightarrow \R$}
\begin{align*}
f(x) & = 0 \implies x = 0, && f(x) \geq 0 \\
f(\alpha \cdot x) & = |\alpha|\cdot f(x) && \text{for scalar } \alpha \\
f(x+y) & \leq f(x) + f(y) && \forall x, y \in R^n
\end{align*}
\tim {Maybe move the above somewhere else?}

\paragraph{General Problem}
$\min_{x \in \dom(f)} f(x)$ s.\ t.\ $g_i(x) \leq 0$ and $h_j(x) = 0.$
%for $i = 1,\dots,m, j = 1,\dots,p$.

\subsection{Linear Programming (LP)}
\paragraph{Problem statement} $\min c^Tx$ such that $\vG x \leq h$ and $\vA x = b$.
\paragraph{Norm $l_\infty$}
$\min_x \lVert x \rVert_\infty = \min_{x \in \R^n} \left[ \max\{x,\dots,x_n,-x_1,\dots,-x_n\}\right]$:
\begin{align*}
     & \min_{x,t} t & \text{subject to}\quad & x_i \leq t, -x_i \leq t,   \; & \vF x \leq g \\
\iff & \min_{x,t} t & \text{subject to}\quad & -{\bm 1} t \leq x \leq 1 t,\; & \vF_x \leq g.
\end{align*}

\paragraph{Norm $l_1$}
$\min_x \lVert x \rVert_1 = \min_x\left[\sum_{i=1}^{m} \max\{x_i,-x_i\}\right]$:
\begin{align*}
     & \min_{t} t_1 + \dots + t_m & \text{subject to}\quad & x_i \leq t_i, -x_i \leq t_i,\; & \vF x \leq g \\
\iff & \min_{t} \remph{\vI}^Tt    & \text{subject to}\quad & -t \leq x \leq t,\;            & \vF_x \leq g.
\end{align*}
Note that for $\dim x = 1$, $l_1$ and $l_\infty$ are the same.

\paragraph{MPC with linear cost}
$J(x_0, u) = \lVert \vP x_N \rVert_p + \sum_{i=\remph{0}}^{N-1} \lVert \vQ x_i \rVert_p + \lVert \vR u_i \rVert_p.$

\tim{Insert here slide 45, lect 4}


\paragraph{Receding Horizon Control -- RHC}

\paragraph{QP with substitution (see also Batch approach)}
\begin{align*}
J^*(x_k) & = \min_u \Me{u^T & x_k^T}\Me{\vH & \vF^T \\ \vF & \vY}\Me{u \\ x_k} \\
\text{s. t. } & \vG\ u \leq w + \vE\ x_k
\end{align*}
Latter gives three sets (same for without substitution)
\begin{align*}
\mc{X}   & = \{ x | A_x\ x \leq b_x\} \\
\mc{U}   & = \{ u | A_u\ u \leq b_u\} \\
\mc{X_f} & = \{ x | A_f\ x \leq b_f\} \\
\end{align*}
State equations are in cost matrix, usually $\vA_x = \Me{1 \\ -1}, b_x = \Me{b_\text{max} \\ -b_\text{min}}$
\begin{scriptsize}
\setlength{\arraycolsep}{2pt}
\begin{align*}
\vG & = \Me{\vA_u & 0 & \dots & 0 \\
          0 & \vA_u & \dots & 0 \\
          \vdots & \vdots & \ddots & \vdots \\
					0      & 0 & \dots & \vA_u \\
					0      & 0 & \dots & 0 \\
					\vA_x\vB & 0 & \dots & 0 \\
					\vA_x\vA\vB & \vA_x\vB & \dots & 0 \\
					\vdots & \vdots & \ddots & \vdots \\
					\vA_x\vA^{N-2}\vB & \vA_x\vA^{N-3}\vB & \dots & 0 \\
					\vA_f\vA^{N-1}\vB & \vA_f\vA^{N-2}\vB & \dots & \vA_f\vB} &
\vE & = \Me{0 \\ 0 \\ \vdots \\ 0 \\ -\vA_x \\ -\vA_x\vA \\ -\vA_x\vA^2 \\ \vdots \\ -\vA_x\vA^{N-1} \\ -\vA_f\vA^N} &
\vW & = \Me{b_u \\ b_u \\ \vdots \\ b_u \\ b_x \\ b_x \\ b_x \\ \vdots \\ b_x \\ b_f}
\end{align*}
\end{scriptsize}

\paragraph{QP with out substitution}
State equations represented in equality constrainst.
\begin{align*}
J^*(x_k) & = \min_z \Me{z^T & x_k^T}\Me{\bar\vH & \bm 0 \\ \bm 0 & \vQ}\Me{z \\ x_k} \\
\text{s. t. } & \vG\ z \leq w + \vE\ x_k \\
              & \vG_\text{eq}\ z = \vE_\text{eq}\ x_k, \quad \text{system dynamics} \\
\end{align*}
$\bar\vH = \diag(\vQ,\dots,\vQ,\vP,\vR,\dots,\vR)$
\begin{scriptsize}
\setlength{\arraycolsep}{2pt}
\begin{align*}
z & = \Me{x_1 \\ . \\ x_N \\ u_0 \\ . \\ u_{N-1}} &
\vG_\text{eq} & =
\begin{bmatrix}[rrrr@{\hskip 2pt}|@{\hskip 2pt}rrrr]
 \vI & \   &  \   & \   & -\vB &  \   & \ &  \ \\
-\vA & \vI &  \   & \   &  \   & -\vB & \ &  \ \\
 \   & .   & .    & \   &  \   &  \   & . &  \ \\
 \   & \   & -\vA & \vI &  \   &  \   & \ & -\vB
\end{bmatrix} &
\vE_\text{eq} & = \Me{\vA \\ 0 \\ . \\ 0} \\
w & = \Me{b_x \\ . \\ b_f \\ b_u \\ . \\ b_u} &
\vG & =
\begin{bmatrix}[cccc|ccc]
 0  & \     & \ & \     & \     & \ & \ \\
 \  & \vA_x & \ & \     & \     & \ & \ \\
 \  & \     & . & \     & \     & \ & \ \\
 \  & \     & \ & \vA_x & \     & \ & \ \\ \cmidrule(lr){1-7}
 \  & \     & \ & \     & \vA_d & \ & \ \\
 \  & \     & \ & \     & \     & . & \ \\
 \  & \     & \ & \     & \     &   & \vA_d
\end{bmatrix} &
\vE & = \Me{-\vA_x^T \\ 0 \\ . \\ 0}
\end{align*}
\end{scriptsize}

\subsection{Duality}
\paragraph{Lagrangian Dual Function}
\begin{align*}
	L(x,\lambda,\nu) & = f(x) + \sum_{i=1}^{m}\lambda_i g_i(x) + \sum_{i=1}^{p}\nu_i h_i(x) \\
	d(\lambda,\nu) & = \inf_{x \in \mc{X}} L(x,\lambda,\nu) \quad \text{ i.e. } \nabla_x L(x, \lambda, \nu) = 0
%	&= \inf_{x \in \mc{X}} \left[ f_0(x)+\sum_{i=1}^{m}\lambda_i f_i(x)+\sum_{i=1}^{p}\nu_i h_i(x)\right]
\end{align*}
\paragraph{Dual Problem (always convex)} 
$\max_{\lambda,\nu} d(\lambda,\nu)$ s.\ t.\ $\lambda \geq 0$. \\
Optimal value is lower bound for primal: $d^* \leq p^*$.

If primal convex, \emph{Slater condition} (strict feasibility) implies \emph{strong duality}:
\begin{align*}
	\left\{x \left| \right. Ax=b, f_i(x)<0, \right\} \neq \emptyset \Rightarrow d^*  = p^*
\end{align*}

\paragraph{Karush-Kuhn-Tucker (KKT) Conditions}
are necessary for optimality (and sufficient if primal convex).
\begin{itemize}
	\item Primal Feasibility:
		\begin{align*}
			f_i(x^*) &\leq 0 \quad i=1,\dots,m\\
			h_i(x^*) &=0 \quad i=1,\dots,p
		\end{align*}
	\item Dual Feasibility:  $\lambda^* \geq 0$
	\item Complementary Slackness:
		\begin{align*}
			\lambda_i^* \cdot f_i(x^*) = 0 \quad \quad i=1,\dots,m
		\end{align*}
	\item Stationarity:
		\begin{align*}
			&\nabla_x L(x^*,\lambda^*,\nu^*) =0 \\
			%&\nabla f_0(x^*) + \sum_{i=1}^m\lambda_i^*\nabla f_i(x^*)+  \sum_{i=1}^p\nu_i^*\nabla h_i(x^*)
		\end{align*}
\end{itemize}

\subsection{Constrained Finite Time Optimal Control (CFTOC)}

\subsection{Invariance}
Def.: $x(k) \in O \implies x(k+1) \in O \forall k$. \\
\begin{align*}
\pre(S) & := \{ x | g(x) \in S\} & = \{ x | Ax \in S \}
\end{align*}

\tim{We need more here, poos. inv. set, max. pos.inv $O_\infty$}

\subsection{Stability and Feasability}
%Recursive Stability, optimal cost is Lyapunov function.
%\tim{What is meant with that}

Main Idea: Choose $\mc X_f$ and $\vP$ to mimic infinite horizon.
LQR control law $\kappa(x) = \vF_\infty x$ from solving DARE.
Set terminal weight $\vP = \vP_\infty$, terminal set $\mc X_f$ as maximal invariant set:
\begin{align*}
x_{k+1} & = \vA x_k + \vB\vF_\infty\ x_k \in \mc X_f & \forall x_k \in \mc X_f & \text{ terminal set invariant} \\
\mc X_f & \subseteq \mc X, \qquad \vF_\infty\ x_k \in \mc U & \forall x_k \in \mc X_f & \text{ constrainst satisfied}
\end{align*}
We get: 1. Positive stage cost function, 2. invariant terminal set by construction, 3. Terminal cost is Lyapunov function with
\[ x_{k+1}^T\vP x_{k+1} - x_k^T\vP x_k = -x_k^T(\vQ + \vF_\infty^T\vR\vF_\infty)x_k \]

%And stage cost is PD-function $\implies$
Extension to non-linear (time-invariant) MPC possible since terminal set and cost do not rely on linearity.

\subsection{Practical Issues}
\[
\Me{\vI-\vA & -\vB \\ \vC & \bm 0}\Me{x_s \\ u_s} = \Me{\bm 0 \\ r} = \Me{\vB_d \hat d \\ r - \vC_d \hat d}
\]
$\min u_s^T\vR_s u_s$ else $\min (\vC x_s - r)^T \vQ_s (\vC x_s - r)$ subject to $x_s = \vA x_s + \vB u_s$.

\paragraph{MPC for tracking}
Target steady-state conditions $x_s = \vA x_s + \vB u_s$ and $y_s = \vC x_s = r$ and constrainsts give:
\begin{align*}
\min_{x_s, u_s} u_s^T \vR u_s & \text{ subj. to } \Me{\vI-\vA & -\vB \\ \vC & \bm 0}\Me{x_s \\ u_s} = \Me{\bm 0 \\ r}, x_s \in \mc X, u_s \in \mc U
\end{align*}
Usually assume $x_s, u_s$ unique and feasible.
If no solution exists, compute closest steady-state ($\min (\vC x_s - r)^T \vQ (\vC x_s - r)$ s.\ t.\ $x_s = \vA x_s + \vB u_s$).

MPC problem to drive $y \rightarrow r$ is:
\begin{align*}
\min_u \lVert y_N - \vC x_s \rVert_{P_y}^2 + \sum_{i=0}^{N-1}\lVert y_i - \vC x_s \rVert_{Q_y}^2 + \lVert u_i - u_s \rVert_R^2
\end{align*}

\paragraph{Delta formulation for reference $r$}
$\Delta x_k = x_k - x_s, \Delta u_k = u_k - u_s$:
\begin{align*}
\min & V_f(\Delta x_N) + \sum_{i=0}^{N-1} \Delta x_i^T\vQ\Delta x_i + \Delta u_i^T \vR \Delta u_i \\
\text{s.t. } & \Delta x_0 = \Delta x_k \\
             & \Delta x_{k+1} = \vA\Delta x_k + \vB \Delta u_k \\ %+ \vB_d\Delta d_k \\
\vH_x x \leq k_x \rightarrow & \vH_x\Delta x \leq k_x - \vH_x x_s \\
\vH_u u \leq k_u \rightarrow & \vH_u\Delta u \leq k_u - \vH_u u_s \\
                 & \Delta x_N \in \mc X_f \quad \text{adjusted accordingly} \\
								 & x_s \oplus \mc X_f \subseteq \mc X \\
								 & \vK\Delta x + u_s \in \mc U
%\Delta d_{k+1} & = \Delta d_k
\end{align*}
Control given by $u_0^* = \Delta u_0^* + u_s$.

\paragraph{Offset free tracking}
\begin{align*}
x_{k+1} &= \vA x_k + \vB u_k + \vB_d d_k \\
d_{k+1} &= d_k \\
y_k     &= \vC x_k + \vC_d d_k 
\end{align*}
Choice of $\vB_d, \vC_d$ requires that $(\vA,\vC)$ is observable and $\Me{\vA-\vI & \vB_d \\ \vC & \vC_d}$ has full column frank (i.e. $\det{} \neq 0$).

If plant has no integrator we can choose $\vB_d = \bm 0$ since $\det(\vA-\vI) \neq 0$.

\tim{What is $y_m$?}
\begin{align*}
\Me{\hat x_{k+1} \\ \hat d_{k+1}} = \Me{\vA & \vB_d \\ \bm 0 & \vI}\Me{\hat x_k \\ \hat d_k} + \Me{\vB \\ \bm 0}u_k + \Me{\vL_x \\ \vL_d}\left(-y_m(k) + \vC\hat x_k + \vC_d \hat d_k\right)
\end{align*}
where $\Me{\vL_x \\ \vL_d}$ stable and causes error dynamics to converge.

\remph{???}
Will always converge if RHC is recursively feasible unconstrained for $k \geq j$.

\paragraph{Soft-constraints via slack variables}

\subsection{Robust MPC}
\paragraph{Enforcing terminal constraints} by robust invariance: \\
\begin{align*}
x \in O^{\mc W} \implies g(x, w) \in \Omega^W \; \forall w \in \mc W \\
\pre^{\mc W}(\Omega) = \left\{ x \middle| g(x, w) \in \Omega \; \forall w \in \mc W\right\}
\end{align*}
\tim{Maybe an example from exercises to compute $O^W_\infty$}

\paragraph{Enforcing sequential constraints} for uncertain system $\phi$:\\
\begin{align*}
\phi_i(x_0, u, w) & = \left\{ x_i + \sum_{j=0}^{i-1}\vA^J w_j \middle| w \in \mc W^i \right\} \subseteq \mc X \\
\phi_N(x_0, u, w) & \in \mc X_f \quad\text{as well}
\end{align*}
\tim{One or two words on what is what}
\begin{align*}
\vA_x x & \leq b_x \text{ becomes } \vA_x x_i + \vA_x \sum_{j=0}^{i-1}\vA^j w_k \leq b_x: \\
x_i & \in \mc X \ominus \left(\mc W \oplus \vA\mc W \oplus \dots \oplus \vA^{i-1}\mc W\right) \\
    & = \left(\bigoplus_{j=0}^{i-1}\vA^j\mc W\right) = \Me{\vA^0 & \dots & \vA^{i-1}}\mc W^i \\
\end{align*}

\paragraph{Tube-MPC}
We want nominal system $z_k = \vA z_k + \vB v_k$ with ``tracking'' controller $u_k = \vK(x_k - z_k) + v_k$, $\vK$ found offline. \\
Step 1: Compute $\mc E = \bigoplus_{j=1}^\infty \vA^j\mc W.$ \\
Step 2: Shrink Constraints:
\begin{align*}
\{z_i\} \oplus \mc E & \subseteq \mc X & \implies z_i & \in \mc X \ominus \mc E \\
u_i \in \vK\mc E \oplus \{v_i\} & \subset \vU & \implies v_i & \in \mc U \ominus \vK\mc E \\
\end{align*}
Also $z_n \in \mc X_f \ominus \mc E$ accordingly.

\subsection{Explicit MPC}

\subsection{Hybrid MPC}

\section{Numerical Optimization}
Gradient, Newton, Interior Point

\end{multicols*}

\end{document}
